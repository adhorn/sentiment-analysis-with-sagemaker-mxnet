{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with MXNet on SageMaker\n",
    "\n",
    "In this notebook, we will build and train a sentiment analysis model with MXNet on SageMaker.\n",
    "Our model will learn to classify movie reviews as positive (1) or negative (0).\n",
    "\n",
    "We will use the SST-2 dataset (Stanford Sentiment Treebank 2), which consists of of movie reviews with one sentence per review.\n",
    "\n",
    "This example is based on [SageMaker PythonSDK example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_gluon_sentiment/sentiment.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Initialization and imports\n",
    "\n",
    "We will start by importing the modules needed, and creating a SageMaker session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset download and preparation\n",
    "\n",
    "Next let's download the datasets into a /data dir, and then upload it to SageMaker's S3 bucket.\n",
    "Each line in the dataset has space separated tokens, the first token being the label: 1 for positive and 0 for negative.\n",
    "\n",
    "We can also check out the downloaded files in Jupyter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training data. We're downloading the Stanford Sentiment dataset\n",
    "# https://nlp.stanford.edu/sentiment/index.html\n",
    "\n",
    "!mkdir data\n",
    "!curl https://raw.githubusercontent.com/saurabh3949/Text-Classification-Datasets/master/stsa.binary.phrases.train > data/train\n",
    "!curl https://raw.githubusercontent.com/saurabh3949/Text-Classification-Datasets/master/stsa.binary.test > data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-968277166688\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/sentiment-analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the training function\n",
    "\n",
    "Now we will wanto to implement the training logic that will run on the SageMaker platform. \n",
    "The training scripts are essentially the same as one you would write for local training,  except that you need to provide a train function with a specific signature. \n",
    "\n",
    "When SageMaker calls your function, it will pass in arguments that describe the training environment. Let's checkout the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 'sentiment-analysis.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the training script on SageMaker\n",
    "\n",
    "SageMaker's MXNet class allows us to run our training function on SageMaker infrastructure. \n",
    "We need to configure it with our training script, an IAM role, the number of training instances, training instance type and hyper parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "m = MXNet(\"sentiment-analysis.py\", \n",
    "          role=role, \n",
    "          train_instance_count=1, \n",
    "          train_instance_type=\"ml.c5.4xlarge\",\n",
    "          hyperparameters={'batch_size': 8, \n",
    "                         'epochs': 2, \n",
    "                         'learning_rate': 0.01, \n",
    "                         'embedding_size': 50, \n",
    "                         'log_interval': 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our MXNet object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-968277166688\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2018-06-15-07-17-04-550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n",
      "\u001b[31m2018-06-15 07:19:19,397 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-06-15 07:19:19,397 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-06-15 07:19:19,403 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-06-15 07:19:21,378 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 0, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'network_interface_name': u'ethwe', u'hosts': [u'algo-1']}, 'user_script_name': u'sentiment-analysis.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'sentiment-analysis.py', u'embedding_size': 50, u'learning_rate': 0.01, u'log_interval': 1000, u'epochs': 2, u'batch_size': 8, u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-2018-06-15-07-17-04-550', u'sagemaker_container_log_level': 20, u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-968277166688/sagemaker-mxnet-2018-06-15-07-17-04-550/source/sourcedir.tar.gz'}, 'hosts': [u'algo-1'], 'job_name': 'sagemaker-mxnet-2018-06-15-07-17-04-550', '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-968277166688/sagemaker-mxnet-2018-06-15-07-17-04-550/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-east-1', '_scheduler_ip': '10.32.0.4', 'input_dir': '/opt/ml/input', 'user_requirements_file': None, 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 16, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-968277166688/sagemaker-mxnet-2018-06-15-07-17-04-550/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-06-15 07:19:21,456 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-06-15 07:19:21,544 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-east-1-968277166688.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-06-15 07:19:21,664 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31mWARNING: discarded 9 sentences longer than the largest bucket.\u001b[0m\n",
      "\u001b[31mWARNING: discarded 27 sentences longer than the largest bucket.\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 1000] Training: accuracy=0.732892, 2599.103950 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 2000] Training: accuracy=0.771739, 1920.798672 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 3000] Training: accuracy=0.796443, 1700.680791 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 4000] Training: accuracy=0.810547, 1450.876984 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 5000] Training: accuracy=0.820811, 1756.316776 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 6000] Training: accuracy=0.827425, 1575.399408 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 7000] Training: accuracy=0.833792, 1777.812440 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 8000] Training: accuracy=0.839114, 1616.146421 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0 Batch 9000] Training: accuracy=0.843101, 1499.237389 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 0] Training: accuracy=0.845577\u001b[0m\n",
      "\u001b[31m[Epoch 0] Validation: accuracy=0.803828\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 1000] Training: accuracy=0.904221, 1476.542662 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 2000] Training: accuracy=0.902924, 1667.383820 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 3000] Training: accuracy=0.901408, 1680.999549 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 4000] Training: accuracy=0.898744, 1728.896950 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 5000] Training: accuracy=0.897271, 1642.409790 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 6000] Training: accuracy=0.897788, 1624.675931 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 7000] Training: accuracy=0.897765, 1566.792678 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 8000] Training: accuracy=0.897028, 1559.728164 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1 Batch 9000] Training: accuracy=0.897261, 1502.056135 samples/s\u001b[0m\n",
      "\u001b[31m[Epoch 1] Training: accuracy=0.896309\u001b[0m\n",
      "\u001b[31m[Epoch 1] Validation: accuracy=0.794258\u001b[0m\n",
      "\u001b[31mVocabulary saved to \"%s\" /opt/ml/model/vocab.json\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 149\n"
     ]
    }
   ],
   "source": [
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting our trained model for inference\n",
    "\n",
    "As can be seen from the logs, we got > 80% accuracy on the test set.\n",
    "After training, we can host the trained MXNet model, and use it for inference.\n",
    "\n",
    "Let's deploy the model, starting with a single C5 instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2018-06-15-06-48-04-494\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2018-06-15-06-48-04-494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the created predictor object and run inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "data = [\"this was an awesome movie!\",\n",
    "        \"come on, you call this a movie?\",\n",
    "        \"best one I've seen in ages\",\n",
    "        \"i just could not watch it till the end.\",\n",
    "        \"the movie was so enthralling !\"]\n",
    "\n",
    "response = predictor.predict(data)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, and do not need the endpoint any more, remember to delete the prediction endpoint to release the instance associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-mxnet-2018-06-15-06-48-04-494\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
